{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Project 1: Higgs Boson Detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import csv\n",
    "from regression_tools import * \n",
    "from preprocessing import *\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def load_data(train_path,test_path):\n",
    "    train_reader=np.genfromtxt(train_path,delimiter=',',skip_header=1,converters={1:lambda s: float(0) if s==b'b' else float(1)})\n",
    "    y_train=train_reader[:,1]\n",
    "    x_train=train_reader[:,2:]\n",
    "    test_reader=np.genfromtxt(test_path,delimiter=',',skip_header=1)\n",
    "    x_test=test_reader[:,2:]\n",
    "    ids_test=test_reader[:,0]\n",
    "    return x_train,y_train,x_test,ids_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print(phi_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def compute_stoch_gradient_ridge(y,tx,w,lambda_):\n",
    "    err=y-tx.dot(w)\n",
    "    if len(y)>1:\n",
    "        dL=-tx.transpose().dot(err)/tx.shape[0]+2*lambda_*w\n",
    "    else:\n",
    "        #print('err is '+str(err))\n",
    "        dL=-tx.reshape(-1,)*err+2*lambda_*w.reshape(-1,)\n",
    "        #print('dL is '+str(np.max(dL)))\n",
    "    return dL\n",
    "\n",
    "def ridge_regression_SGD(y, tx, lambda_, initial_w, batch_size, max_iters, gamma):\n",
    "    w=initial_w\n",
    "    for n_iter in range(max_iters):\n",
    "        for mini_y,mini_tx in batch_iter(y,tx,batch_size):\n",
    "            g=compute_stoch_gradient_ridge(mini_y,mini_tx,w,lambda_)\n",
    "            w=w-gamma*g\n",
    "            #print(np.max(w))\n",
    "    #print(w.shape)\n",
    "    loss=np.linalg.norm(y-tx.dot(w))**2/(2*len(y))+lambda_*np.linalg.norm(w)**2\n",
    "    return loss, w"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test di durata e ordine di grandezza Learning Rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#test di durata soluzione analitica vs SGD preparazione dati\n",
    "x_train,y_train,x_test,ids_test=load_data('train.csv','test.csv')\n",
    "x_train_cleaned,aa=cleaning_function(x_train)\n",
    "x_train_cleaned,aaa=features_augmentation(x_train_cleaned,not_augm_features=aa+1)\n",
    "x_train_cleaned=norm_data(x_train_cleaned,not_norm_features=aa+1)\n",
    "phi_train=build_polinomial(x_train_cleaned,degree=12,not_poly_features=aa+aaa+1)\n",
    "lambda_=10**-5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.886281967163086\n",
      "(800,)\n"
     ]
    }
   ],
   "source": [
    "#test di durata soluzione analitica vs SGD: calcolo soluzione analitica\n",
    "import time\n",
    "\n",
    "start = time.time()\n",
    "loss,w=ridge_regression(y_train,phi_train,lambda_)\n",
    "end = time.time()\n",
    "print(end - start)\n",
    "print(w.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "64.1861960887909\n"
     ]
    }
   ],
   "source": [
    "#test di durata soluzione analitica vs SGD: calcolo SGD\n",
    "initial_w=np.zeros((len(w),))\n",
    "batch_size=1\n",
    "max_iters=50\n",
    "gamma=10**-19\n",
    "start=time.time()\n",
    "loss_r, w_r =ridge_regression_SGD(y_train,phi_train,lambda_,initial_w, batch_size, max_iters, gamma)\n",
    "end=time.time()\n",
    "print(end-start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11.5509960081 -0.0303506034305\n"
     ]
    }
   ],
   "source": [
    "print(np.max(w_r/w),np.min(w_r/w))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#x_train,nmc_tr=cleaning_function(x_train,-999)\n",
    "#x_test,nmc_te=cleaning_function(x_test,-999)\n",
    "# nmc= nb of not measured column, i.e. columns where \n",
    "#it is present at least one not measured element\n",
    "#phi_train=build_polinomial(x_train,4,nmc_tr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print(phi_train[3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def build_k_indices(y, k_fold, seed):\n",
    "    \"\"\"build k indices for k-fold.\"\"\"\n",
    "    num_row = y.shape[0]\n",
    "    interval = int(num_row / k_fold)\n",
    "    np.random.seed(seed)\n",
    "    indices = np.random.permutation(num_row)\n",
    "    k_indices = [indices[k * interval: (k + 1) * interval]\n",
    "                 for k in range(k_fold)]\n",
    "    return np.array(k_indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def LOO_cross_validation(y, phi, k_indices, k, lambda_, degree, not_poly_features):\n",
    "    \"\"\"return the loss of ridge/linear regression.\"\"\"\n",
    "    \"\"\"Probabilmente conviene implementare una per la regressione normale, in modo da capire \n",
    "    quale sia il grado massimo oltre il quale non ha senso andare e poi lavorare con lambda \n",
    "    per capire come eliminare feature\"\"\"\n",
    "    \n",
    "    \n",
    "    # Get k'th subgroup in test, others in train    \n",
    "    train_indices = np.delete(k_indices , k , 0).reshape((k_indices.shape[0]-1) * k_indices.shape[1])\n",
    "    x_test = phi[k_indices[k],:]\n",
    "    x_train = phi[train_indices,:]\n",
    "    y_test = y[k_indices[k]]\n",
    "    y_train = y[train_indices]\n",
    "    \n",
    "    # Form data with polynomial degree\n",
    "    tx_train = build_polinomial(x_train, degree, not_poly_features)\n",
    "    tx_test = build_polinomial(x_test, degree, not_poly_features)\n",
    "    #print(tx_test.shape)\n",
    "    #print(tx_train.shape)\n",
    "    #print(y_train.shape)\n",
    "    \n",
    "    \n",
    "    # Ridge regression / Linear regression\n",
    "    #if tx_train.shape[1]<50:\n",
    "    if lambda_!=0:\n",
    "        loss , w = ridge_regression(y_train, tx_train, lambda_)\n",
    "    else:\n",
    "        loss , w = least_squares(y_train,tx_train)\n",
    "            \n",
    "    #else: \n",
    "        # forse Ã¨ meglio implementarle all'esterno della funzione\n",
    "        #initial_w=np.ones((tx_train.shape[1]))\n",
    "        #batch_size=1\n",
    "        #max_iters=100\n",
    "        #gamma=0.01\n",
    "        #if lambda_!=0:\n",
    "        #    loss , w = ridge_regression_SGD(y_train, tx_train, lambda_,initial_w, batch_size, max_iters, gamma)\n",
    "        #else:\n",
    "        #    loss , w = least_squares_SGD(y_train,tx_train,initial_w, batch_size, max_iters, gamma)\n",
    "        \n",
    "    \n",
    "    \n",
    "    #print('REGRESSION DONE')\n",
    "    #print(y_test.shape)\n",
    "    #print(w.shape)\n",
    "    \n",
    "    # Calculate results\n",
    "    result=(y_test==(tx_test.dot(w)>0.5)).sum()/y_test.shape[0]\n",
    "    #print('RESULT CALCULATED')\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#def cross_validation_degree():\n",
    "def cross_validation_demo(y_train,x_train,degrees,k_fold,lambdas,seed):\n",
    "\n",
    "    # split data in k fold\n",
    "    k_indices = build_k_indices(y_train, k_fold, seed)\n",
    "\n",
    "\n",
    "    # Clean data \n",
    "    x_train_cleaned,nmc_tr=cleaning_function(x_train,-999)\n",
    "    #feature augmentation\n",
    "    x_train_cleaned,noaf=features_augmentation(x_train_cleaned,not_augm_features=nmc_tr+1)\n",
    "\n",
    "    # cross validation\n",
    "    cost_te=np.zeros((lambdas.size,degrees.size))\n",
    "    for ind_lamb,lambda_ in enumerate(lambdas):\n",
    "        print(lambda_)\n",
    "        if lambda_!=0:\n",
    "            x_train_cleaned=norm_data(x_train_cleaned,not_norm_features=noaf+nmc_tr+1)\n",
    "        for ind_deg, degree_ in enumerate(degrees):\n",
    "            #print('DEGREE IS: ')\n",
    "            #print(degree_)\n",
    "            loss_te = np.zeros(k_fold)\n",
    "            for k in range (k_fold):\n",
    "                #print('K CONSIDERED IS: ')\n",
    "                #print(k)\n",
    "                result = LOO_cross_validation(y_train, x_train_cleaned, k_indices, k , lambda_, degree_, nmc_tr+1+noaf)\n",
    "                loss_te[k]= result\n",
    "\n",
    "            cost_te[ind_lamb,ind_deg]=loss_te.mean()\n",
    "    return cost_te\n",
    "\n",
    "\n",
    "    #cross_validation_degree()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Plot the results  \n",
    "def plot_cross_validation(lambdas,cost_te,degrees):\n",
    "    plt.figure\n",
    "    string=[]\n",
    "    for s in range(lambdas.size):\n",
    "        plt.plot(degrees,cost_te[s])\n",
    "        string.append(str(lambdas[s]))\n",
    "    plt.xlabel('degree')\n",
    "    plt.ylabel('train accuracy')\n",
    "    plt.legend(string)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def find_the_maximum(matrix):\n",
    "    max_col=np.max(matrix,axis=0)\n",
    "    max_col_ind=np.max(np.argmax(max_col))\n",
    "    max_matrix=np.max(max_col)\n",
    "    max_row_ind=np.min(np.argmax(matrix[:,max_col_ind]))\n",
    "    return max_matrix,[max_row_ind,max_col_ind] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def create_csv_submission(ids, y_pred, name):\n",
    "    \"\"\"\n",
    "    Creates an output file in csv format for submission to kaggle\n",
    "    Arguments: ids (event ids associated with each prediction)\n",
    "               y_pred (predicted class labels)\n",
    "               name (string name of .csv output file to be created)\n",
    "    \"\"\"\n",
    "    with open(name, 'w') as csvfile:\n",
    "        fieldnames = ['Id', 'Prediction']\n",
    "        writer = csv.DictWriter(csvfile, delimiter=\",\", fieldnames=fieldnames)\n",
    "        writer.writeheader()\n",
    "        for r1, r2 in zip(ids, y_pred):\n",
    "            writer.writerow({'Id':int(r1),'Prediction':int(r2)})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "x_train,y_train,x_test,ids_test=load_data('train.csv','test.csv')\n",
    "seed = 1\n",
    "degrees = np.arange(5,16)\n",
    "k_fold = 4\n",
    "# To use ridge regression\n",
    "lambdas = np.logspace(-8,-1,num=5)\n",
    "print(lambdas.size)\n",
    "cost_te=cross_validation_demo(y_train,x_train,degrees,k_fold,lambdas,seed)\n",
    "plot_cross_validation(lambdas,cost_te,degrees)\n",
    "_,best_param_ind=find_the_maximum(cost_te)\n",
    "print('best degree is '+str(degrees[best_param_ind[1]]))\n",
    "print('best lambda is '+str(lambdas[best_param_ind[0]]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# continuation of the previous script\n",
    "x_train_cleaned,nmc_tr=cleaning_function(x_train,-999)\n",
    "x_train_cleaned=norm_data(x_train_cleaned,not_norm_features=nmc_tr+1)\n",
    "phi_tr=build_polinomial(x_train_cleaned,degree=degrees[best_param_ind[1]],not_poly_features=nmc_tr+1)\n",
    "loss,w=ridge_regression(y_train,phi_tr,lambdas[best_param_ind[0]])\n",
    "x_test_cleaned,nmc_te=cleaning_function(x_test,-999)\n",
    "x_test_cleaned=norm_data(x_test_cleaned,not_norm_features=nmc_te+1)\n",
    "phi_te=build_polinomial(x_test_cleaned,degree=degrees[best_param_ind[1]],not_poly_features=nmc_te+1)\n",
    "y_test=phi_te.dot(w)\n",
    "y_pred=[]\n",
    "for i in range(y_test.shape[0]):\n",
    "    if y_test[i]>0.5:\n",
    "        y_pred.append(1)\n",
    "    else:\n",
    "        y_pred.append(-1)\n",
    "        #b=-1\n",
    "        \n",
    "create_csv_submission(ids_test, y_pred, 'submission.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print(y_test.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print(ids_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "? np.genfromtxt()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "np.nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "? np.mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "? np.argmax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "a=np.array([1,2,3,4,5])\n",
    "b=np.concatenate([a.reshape(-1,1),a.reshape(-1,1)],axis=1)\n",
    "print(b,a[0:1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "? np.array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 2 3 4]\n"
     ]
    }
   ],
   "source": [
    "diego=np.array([1,2,3,4])\n",
    "print(diego.reshape(-1,)*1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
